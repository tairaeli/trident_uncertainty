{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "4514ca1d-b483-49d2-a346-4b9778d75d6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[[4, 5]]]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def _check_interval(index_list, entries=[0,1], check_num=3, iteration=[0,1]):\n",
    "    index_list.append([[iteration[0], iteration[1]] for num in range(check_num) if entries[0]+num==entries[1]])\n",
    "    return index_list\n",
    "    \n",
    "mylist = _check_interval(102, 103, 3, [], 4, 5)\n",
    "mylist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d0353456-5996-41fc-9098-160de60d4f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def _sort_indices(master):\n",
    "    \n",
    "    \"\"\"\n",
    "    gets index list ready for manipulating dataset rows\n",
    "    \n",
    "    :master: list to be sorted -- generated by _check_absorber_int()\n",
    "    \"\"\"\n",
    "    \n",
    "    for index in range(len(master)-1):\n",
    "        \n",
    "        if index+1 >= len(master):\n",
    "            break\n",
    "    \n",
    "        else:\n",
    "            \n",
    "            if master[index] == master[index+1]:\n",
    "                del master[index+1]\n",
    "            \n",
    "            if master[index][1] == master[index+1][0]:\n",
    "                master[index].append(master[index+1][1])\n",
    "                del master[index+1]\n",
    "                \n",
    "    return master\n",
    "\n",
    "\n",
    "\n",
    "def _check_interval(entry1, entry2, check_num, index_list, iteration1, iteration2):\n",
    "    \n",
    "    \"\"\"\n",
    "    checks entries in given consecutive rows -- if they're close enough to the same value, index numbers returned as a list to be added to a master list of all indices to be changed. Used in _check_absorber_int()\n",
    "    \n",
    "    :entry1: value of lower row number to be checked\n",
    "    \n",
    "    :entry2: value of upper row number to be checked\n",
    "    \n",
    "    :check_num: integer -- maximum value used to determine whether the interval needs to be modified for the given set of indices\n",
    "    \n",
    "    :index_list: list in which index numbers will be stroed so we know what to fix\n",
    "    \n",
    "    :iteration1: index (row) number of entry1\n",
    "    \n",
    "    :iteration2: index (row) number of entry2\n",
    "    \"\"\"\n",
    "    \n",
    "    index_list.append([iteration1, iteration2] for num in range(check_num) if entry1+num==entry2)\n",
    "    \n",
    "#     for num in range(check_num):\n",
    "        \n",
    "#         if entry1+num == entry2:\n",
    "#             index_list.append([iteration1, iteration2])\n",
    "#         else:\n",
    "#             pass\n",
    "\n",
    "        \n",
    "        \n",
    "def _check_absorber_int(data, indices, check_num=3):\n",
    "    \n",
    "    \"\"\"\n",
    "    Determines if absorber intervals need to be checked for a given dataset or set of datasets by looping through ions in a given dataset (such information stored in \"indices\" parameter). If yes, calls _check_interval() and _sort_indices(). Returns a dictionary of row numbers corresponding to absorbers that need to be combined.\n",
    "    \n",
    "    :data: dictionary containing all pandas DataFrames to be checked\n",
    "    \n",
    "    :indices: dictionary generated in record_indices(). Contains the number of lightray indices for a given ion in a given dataset\n",
    "    \n",
    "    :check_num: integer -- maximum value used to determine whether the interval needs to be modified for the given set of indices. Default is 3. \n",
    "    \"\"\"\n",
    "    \n",
    "    ind = {}\n",
    "    master = {}\n",
    "    \n",
    "    for ds in data:\n",
    "        index_list = []\n",
    "        \n",
    "        for key in indices.keys():\n",
    "            problem_list = indices[key]\n",
    "            \n",
    "            for index in problem_list:\n",
    "                \n",
    "                if index == 0:\n",
    "                    pass\n",
    "\n",
    "                else:\n",
    "\n",
    "                    if data[ds]['lightray_index'].iloc[index] == data[ds]['lightray_index'].iloc[index-1]:\n",
    "\n",
    "                        _check_interval(data[ds]['interval_start'].iloc[index], data[ds]['interval_start'].iloc[index+1], check_num, index_list, index-1, index)\n",
    "                        _check_interval(data[ds]['interval_start'].iloc[index], data[ds]['interval_end'].iloc[index+1], check_num, index_list, index-1, index)\n",
    "                        _check_interval(data[ds]['interval_end'].iloc[index], data[ds]['interval_start'].iloc[index+1], check_num, index_list, index-1, index)\n",
    "                        _check_interval(data[ds]['interval_end'].iloc[index], data[ds]['interval_end'].iloc[index+1], check_num, index_list, index-1, index)\n",
    "\n",
    "                    else:\n",
    "\n",
    "                        pass\n",
    "                    \n",
    "            ind[f'{ds}_indexlist'] = index_list\n",
    "            \n",
    "    for indl in ind:\n",
    "        ind[indl].sort()\n",
    "        master[f'{indl}'] = _sort_indices(ind[indl])\n",
    "        \n",
    "    return master\n",
    "\n",
    "\n",
    "\n",
    "def _find_index_range(dataset, ion):\n",
    "    \n",
    "    \"\"\"\n",
    "    for a given dataset and ion, determines the number of absorbers dedicated to that ion in that dataset. Returns as a list a range of row numbers to be checked against the same ions in other datasets. \n",
    "    \n",
    "    :dataset: one of the datasets contained in the dictionary of pandas DataFrames\n",
    "    \n",
    "    :ion: string. Used for indexing to obtain row numbers\n",
    "    \"\"\"\n",
    "    \n",
    "    index_range = []\n",
    "    \n",
    "    for index in range(len(dataset['name'])):\n",
    "        \n",
    "        if dataset['name'].iloc[index] == ion:\n",
    "            index_range.append(index)\n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "    return index_range\n",
    "\n",
    "\n",
    "\n",
    "def record_indices(dic):\n",
    "    \"\"\"\n",
    "    Generates a dictionary (\"data\") containing information on the number of rows/absorbers dedicated to a specific ion in a dataset. Each dataset is a primary key in the dataset. Ions and their number of absorbers found in each dataset are stored as dictionaries within its primary key. \"Data\" is used to produce a dictionary of indices to be checked by _check_absorber_int()\n",
    "    \n",
    "    :dic: dictionary containing each dataset as a pandas DataFrame\n",
    "    \"\"\"\n",
    "    \n",
    "    data = {}\n",
    "    indices = {}\n",
    "\n",
    "    for i in range(len(dic.keys())):\n",
    "        data[f'data{i}'] = {}\n",
    "\n",
    "    for ds in dic:\n",
    "\n",
    "        for index in range(len(dic[ds]['name'])):\n",
    "\n",
    "            if index == 0:\n",
    "                data[ds][f\"{dic[ds]['name'].iloc[index]}\"] = {}\n",
    "                data[ds][f'{dic[ds][\"name\"].iloc[index]}'][f'{dic[ds][\"lightray_index\"].iloc[index]}'] = 1\n",
    "            else:\n",
    "\n",
    "                if dic[ds]['name'].iloc[index] == dic[ds]['name'].iloc[index-1]:\n",
    "\n",
    "                    if dic[ds]['lightray_index'].iloc[index] == dic[ds]['lightray_index'].iloc[index-1]:\n",
    "                        data[ds][f'{dic[ds][\"name\"].iloc[index]}'][f'{dic[ds][\"lightray_index\"].iloc[index]}'] += 1\n",
    "                    else:\n",
    "                        data[ds][f'{dic[ds][\"name\"].iloc[index]}'][f'{dic[ds][\"lightray_index\"].iloc[index]}'] = 1\n",
    "\n",
    "                else:\n",
    "                    data[ds][f'{dic[ds][\"name\"].iloc[index]}'] = {}\n",
    "                    data[ds][f'{dic[ds][\"name\"].iloc[index]}'][f'{dic[ds][\"lightray_index\"].iloc[index]}'] = 1\n",
    "                    \n",
    "        for ds in range(len(data.keys())-1):\n",
    "            \n",
    "            for key in data[f'data{ds}'].keys():\n",
    "                \n",
    "                if key not in data[f'data{ds+1}']:\n",
    "                    pass\n",
    "                else:\n",
    "                    indices[f'{key}'] = _find_index_range(dic[f'data{ds}'], key)\n",
    "\n",
    "    return data, indices\n",
    "           \n",
    "        \n",
    "        \n",
    "def check_abs_differences(filename_list, override=False, **kwargs):\n",
    "    \"\"\"\n",
    "    Called by user. Loads datasets as pandas DataFrames and stores them in a dictionary for ease of indexing. If the datasets are not the same length, an inconsistency in the number of absorbers for a given ion and lightray_index is assumed. record_indices() and _check_absorber_int()are called, ultimately returning a dictionary of row numbers relating to absorbers that need to be combined. \n",
    "    \n",
    "    :filename_list: list containing path and filename for each dataset. Files can have any name, but are referred to as \"data{i} throughout the rest of the process (where \"i\" is a different integer related to filename's place in the list)\"\n",
    "    \n",
    "    :kwargs: keyword arguments to be passed to pandas.read_csv() for the purpose of loading the data\n",
    "    \"\"\"\n",
    "    \n",
    "    data_lengths = []\n",
    "    dic = {}\n",
    "    rec_ind = 0\n",
    "    \n",
    "    for i in range(len(filename_list)):\n",
    "        dic[f'data{i}'] = pd.read_csv(filename_list[i], **kwargs)\n",
    "        data_lengths.append(len(dic[f'data{i}']))\n",
    "    \n",
    "    for num in range(len(data_lengths)-1):\n",
    "        if data_lengths[num] == data_lengths[num+1]:\n",
    "            pass\n",
    "        else:\n",
    "            rec_ind += 1\n",
    "    \n",
    "    if rec_ind != 0 or override==True:\n",
    "        data, indices = record_indices(dic)\n",
    "        data_count = 0\n",
    "        \n",
    "        for i in range(len(data.keys())-1):\n",
    "            for key in data[f'data{i}'].keys():\n",
    "                if data[f'data{i}'][key] == data[f'data{i+1}'][key]:\n",
    "                    data_count += 1\n",
    "                else:\n",
    "                    pass\n",
    "                \n",
    "        if data_count != 0:\n",
    "            print('all is gucci babyyyyyy')\n",
    "            return ['bitch']\n",
    "        else:\n",
    "            master = _check_absorber_int(dic, indices)\n",
    "            mast_count = 0\n",
    "\n",
    "            for x in range(len(master)-1):\n",
    "                if master[f'data{indl}_indexlist'] == master[f'data{indl+1}_indexlist']:\n",
    "                    pass\n",
    "                else:\n",
    "                    mast_count += 1\n",
    "\n",
    "            if mast_count == 0:\n",
    "                return master['data0_indexlist']\n",
    "            else:\n",
    "                return master\n",
    "\n",
    "    else:\n",
    "        print('all is gucci babyyyyyy')\n",
    "        return ['bitch']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "71925666-5246-456f-a8dc-8eb04b60e1c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nfilename_list = ['../test_sal/interval_tests/data/ionlist0data_.csv', '../test_sal/interval_tests/data/ionlist1data_.csv', '../test_sal/interval_tests/data/ionlist2data_.csv']\\nkwargs = dict(delim_whitespace=True)\\nthing=check_abs_differences(filename_list, **kwargs)\\n\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "filename_list = ['../test_sal/interval_tests/data/ionlist0data_.csv', '../test_sal/interval_tests/data/ionlist1data_.csv', '../test_sal/interval_tests/data/ionlist2data_.csv']\n",
    "kwargs = dict(delim_whitespace=True)\n",
    "thing=check_abs_differences(filename_list, **kwargs)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "207f551c-1883-495a-84e5-593afaafcb26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nimport pandas as pd\\npath = '../test_sal/interval_tests/data/ionlist0data_.csv'\\ndf = pd.read_csv(path, delim_whitespace=True)\\n\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "import pandas as pd\n",
    "path = '../test_sal/interval_tests/data/ionlist0data_.csv'\n",
    "df = pd.read_csv(path, delim_whitespace=True)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "767486e7-8a41-4ef3-8ad6-23e18302cec4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all is gucci babyyyyyy\n"
     ]
    }
   ],
   "source": [
    "filename_list = []\n",
    "for i in range(25):\n",
    "    filename_list.append(f\"../test_sal/abundance_test3/data/data_row{i}_.csv\")\n",
    "\n",
    "kwargs = dict(delim_whitespace=True)\n",
    "thing = check_abs_differences(filename_list, override=True, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c5040842-3c8f-46bc-b1ad-4270bbc8e709",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bitch']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc49e6d-96d4-4a9d-8d27-630676909641",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
